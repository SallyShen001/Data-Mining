# Data-Mining
a. Machine Learning :allows computers to “learn” like humans without any need of explicit programming.
b. Predictive Modeling:a probabilistic process that allows us to forecast outcomes, on the basis of some predictors.These predictors are basically features that come into play when deciding the final result, i.e. the outcome of the model.
c. Dimensionality reduction:the process of reducing the number of features (or dimensions) in a dataset while retaining as much information as possible
    This can be done for a variety of reasons, such as to reduce the complexity of a model, to improve the performance of a learning algorithm, or to make it easier to visualize the data. it is a process of transforming high-dimensional data into a lower-dimensional space that still preserves the essence of the original data
    There are several techniques for dimensionality reduction, including principal component analysis (PCA), singular value decomposition (SVD), and linear discriminant analysis (LDA). Each technique uses a different method to project the data onto a lower-dimensional space while preserving important information.

d.Dimensionality reduction:a technique used to reduce the number of features in a dataset while retaining as much of the important information as possible.A process of transforming high-dimensional data into a lower-dimensional space that still preserves the essence of the original data.
    Two main approaches to dimensionality reduction: feature selection and feature extraction.

e. Feature Selection:selecting a subset of the original features that are most relevant to the problem at hand. The goal is to reduce the dimensionality of the dataset while retaining the most important features.
  There are several methods for feature selection, including (1)filter methods, (2)wrapper methods, and (3)embedded methods. 
  - Filter methods rank the features based on their relevance to the target variable,
  - wrapper methods use the model performance as the criteria for selecting features,
  - embedded methods combine feature selection with the model training process.
f. Feature Extraction:creating new features by combining or transforming the original features.The goal is to create a set of features that captures the essence of the original data in a lower-dimensional space.
  There are several methods for feature extraction, including principal component analysis (PCA), linear discriminant analysis (LDA), and t-distributed stochastic neighbor embedding (t-SNE).
   PCA is a popular technique that projects the original features onto a lower-dimensional space while preserving as much of the variance as possible.

